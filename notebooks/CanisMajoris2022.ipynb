{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ab874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from performer.models.ddsp_module import DDSP\n",
    "from performer.datamodules.components.ddsp_dataset import DDSPDataset\n",
    "\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795722d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vln_ckpt = '../checkpoints/violin_longrun.ckpt'\n",
    "vlc_ckpt = '../checkpoints/cello_longrun.ckpt'\n",
    "flt_ckpt = '../checkpoints/flute_longrun.ckpt'\n",
    "\n",
    "vln_data = \"../data/violin_samples.pth\"\n",
    "vlc_data = \"../data/cello_samples.pth\"\n",
    "flt_data = \"../data/flute_samples.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [vln_data, vlc_data, flt_data]:\n",
    "    dataset = DDSPDataset(path)\n",
    "    print(path, dataset.loudness.mean(), dataset.loudness.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_hz(midi: float) -> float:\n",
    "    return 440. * 2**((midi - 69) / 12)\n",
    "\n",
    "def hz_to_midi(hz: float) -> float:\n",
    "    return 12 * torch.log2(hz / 440) + 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73409d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adsr(\n",
    "    ts: float, a: float, d: float, r:float, zero: float = 0., peak: float = 1., s: float = 0.5\n",
    ") -> torch.Tensor:\n",
    "    attack = torch.linspace(zero, peak, int(a * 250))\n",
    "    decay = torch.linspace(peak, s, int(d * 250))\n",
    "    sustain = torch.ones(int(ts * 250)) * s\n",
    "    release = torch.linspace(s, zero, int(r * 250))\n",
    "\n",
    "    env = torch.cat([attack, decay, sustain, release])[None, None, :].cuda()\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741beed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin(ts: float, f: float):\n",
    "    t = torch.arange(int(ts * 250), dtype=torch.float32, device='cuda') / 250\n",
    "    result = torch.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def sin_like(ts: torch.Tensor, f: float):\n",
    "    t = torch.arange(ts.shape[-1], dtype=torch.float32, device='cuda') / 250\n",
    "    result = torch.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18be836",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model = DDSP.load_from_checkpoint(flt_ckpt, map_location='cuda')\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amp = adsr(2, 0.05, 0.07, 1, -100, -16, -46) + 2 * sin(3.117, 4)\n",
    "zero, peak, sus, std = -100, -48+15*2, -48, 15\n",
    "a, d, s, r = 0.1, 0.4, 1, 2\n",
    "\n",
    "attack = torch.linspace(zero, peak, int(a*250), device='cuda')\n",
    "decay = torch.linspace(peak, sus, int(d*250), device='cuda')\n",
    "sustain = torch.linspace(sus, sus+std, int(s*250), device='cuda')\n",
    "release = torch.linspace(sus+std, zero, int(r*250), device='cuda')\n",
    "silence = torch.ones(int(4*250), device='cuda') * zero\n",
    "\n",
    "amp = torch.cat([attack, decay, sustain, release, silence])\n",
    "\n",
    "amp += torch.randn_like(amp) * 0.01\n",
    "f0 = torch.ones_like(amp, device='cuda') * 59.\n",
    "f0 += sin_like(f0, 4) * 0.125\n",
    "f0[-6*250:] += 3\n",
    "f0 = midi_to_hz(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y = model(f0[None, None, :], amp[None, None, :])\n",
    "\n",
    "_y = y.cpu().numpy().squeeze()\n",
    "\n",
    "Audio(data=_y, rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d7eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
