{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ab874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import librosa\n",
    "from soundfile import write\n",
    "import music21\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import math\n",
    "from itertools import permutations\n",
    "\n",
    "from performer.models.ddsp_module import DDSP\n",
    "from performer.datamodules.components.ddsp_dataset import DDSPDataset\n",
    "\n",
    "from IPython.display import Audio, Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9062ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = music21.environment.UserSettings()\n",
    "us['musescoreDirectPNGPath'] = '/usr/bin/musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795722d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_ckpt = '../checkpoints/flute_longrun.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_hz(midi: float) -> float:\n",
    "    return 440. * 2**((midi - 69) / 12)\n",
    "\n",
    "def hz_to_midi(hz: float) -> float:\n",
    "    return 12 * torch.log2(hz / 440) + 69\n",
    "\n",
    "def ratio_to_interval(ratio):\n",
    "    return 12 * torch.log2(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e975f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adsr(ta, td, tr, zero, peak, sustain, dur):\n",
    "    ts = dur - ta - td - tr\n",
    "    \n",
    "    env_a = torch.linspace(zero, peak, round(ta * 250))\n",
    "    env_d = torch.linspace(peak, sustain, round(td * 250))\n",
    "    env_sus = torch.ones(round(ts * 250)) * sustain\n",
    "    env_rel = torch.linspace(sustain, zero, round(tr * 250))\n",
    "\n",
    "    env = torch.cat([env_a, env_d, env_sus, env_rel]).cuda()\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741beed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin(ts: float, f: float):\n",
    "    t = torch.arange(int(ts * 250), dtype=torch.float32, device='cuda') / 250\n",
    "    result = torch.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def sin_like(ts: torch.Tensor, f: float):\n",
    "    t = torch.arange(ts.shape[-1], dtype=torch.float32, device='cuda') / 250\n",
    "    result = torch.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(music):\n",
    "    display(Image(str(music.write(\"lily.png\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_microtone(note):\n",
    "    cents = note.pitch.microtone.cents\n",
    "    prefix = ''\n",
    "    if cents > 0:\n",
    "        prefix = '+'\n",
    "    if abs(cents) >= 10:\n",
    "        note.addLyric(f'{prefix}{int(np.round(cents))}', applyRaw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18be836",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model = DDSP.load_from_checkpoint(flt_ckpt, map_location='cuda')\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = random.Random(123)\n",
    "beat = 0.75  # 1 beat is 0.75 seconds\n",
    "fps = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_measure(p1, p2):\n",
    "    one = music21.note.Note(quarterLength=1/3)\n",
    "    one.pitch.frequency = p1\n",
    "    add_microtone(one)\n",
    "\n",
    "    two = music21.note.Note(quarterLength=1/3)\n",
    "    two.pitch.frequency = p2\n",
    "    two.articulations.append(music21.articulations.Staccato())\n",
    "    add_microtone(two)\n",
    "\n",
    "    sl1 = music21.spanner.Slur([one, two])\n",
    "\n",
    "    rest1 = music21.note.Rest(1/3)\n",
    "    rest = music21.note.Rest(4)\n",
    "\n",
    "    m01 = music21.stream.Measure(number=1)\n",
    "\n",
    "    m01.append(music21.dynamics.Dynamic('sfz'))\n",
    "    m01.append(one)\n",
    "    m01.append(two)\n",
    "    m01.append(sl1)\n",
    "    m01.append(rest1)\n",
    "    m01.append(rest)\n",
    "    \n",
    "    return m01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6345098",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = music21.stream.Measure()\n",
    "for val in constant:\n",
    "    nn = music21.note.Note()\n",
    "    freq = midi_to_hz(ratio_to_interval(torch.tensor(val)) + 51)\n",
    "    nn.pitch.frequency = freq\n",
    "    print(nn.pitch.name, nn.pitch.midi, nn.pitch.microtone)\n",
    "    mm.append(nn)\n",
    "mm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = [2, 3, 5, 7, 11/2, 13/2, 17/4, 19/4]\n",
    "\n",
    "amp = adsr(0.1, 0.7, 0.01, -100, -8, -48, 1.5 * beat)\n",
    "silence = torch.ones(round(3.5 * beat * fps), device='cuda') * -100.\n",
    "env = torch.cat([amp, silence], dim=-1)\n",
    "\n",
    "\n",
    "s = music21.stream.Score(id='mainScore')\n",
    "part0 = music21.stream.Part(id='part0')\n",
    "part1 = music21.stream.Part(id='part1')\n",
    "\n",
    "\n",
    "ys = []\n",
    "parts = [part0, part1]\n",
    "lines = [\n",
    "    [(0, 1), (2, 4), (7, 4), (5, 2), (7, 5), (7, 6), (7, 6), (7, 6)],\n",
    "    [(7, 5), (2, 3), (7, 3), (3, 0), (1, 0), (3, 1), (4, 5), (3, 0)],\n",
    "]\n",
    "for part, line in zip(parts, lines):\n",
    "    oll = []\n",
    "    for idx1, idx2 in line:\n",
    "        with torch.inference_mode():\n",
    "            p1 = midi_to_hz(ratio_to_interval(torch.tensor(constant[idx1])) + 51)\n",
    "            p2 = midi_to_hz(ratio_to_interval(torch.tensor(constant[idx2])) + 51)\n",
    "            mezura = build_measure(p1, p2)\n",
    "            # if j % 3 == 2:\n",
    "            #     mezura.append(music21.layout.SystemLayout(isNew=True))\n",
    "            part.append(mezura)\n",
    "            \n",
    "            f0 = torch.ones_like(env) * p2\n",
    "            f0[:int(beat*0.333*fps)] = p1\n",
    "            y = model(f0[None, None, :], env[None, None, :])\n",
    "            oll.append(y)\n",
    "\n",
    "    ys.append(torch.cat(oll, dim=-1).cpu().numpy().squeeze())\n",
    "\n",
    "\n",
    "tempo = music21.tempo.MetronomeMark(referent=1.0, number=90.0)\n",
    "\n",
    "for part in parts:\n",
    "    part.measure(1).insert(tempo)\n",
    "    part.insert(0, music21.meter.TimeSignature('5/4'))\n",
    "    s.insert(0, part)\n",
    "\n",
    "f0 = midi_to_hz(torch.ones_like(env, device='cuda') * 51-12)\n",
    "amp = adsr(0.1, 0.7, 0.01, -100, -3, -48, 2.5 * beat)\n",
    "silence = torch.ones(round(2.5 * beat * fps), device='cuda') * -100.\n",
    "env = torch.cat([amp, silence], dim=-1)\n",
    "oll = []\n",
    "for _ in range(8):\n",
    "    with torch.inference_mode():\n",
    "        y = model(f0[None, None, :], env[None, None, :])  # * (torch.randn(1, device='cuda') * 0.25 + 1))\n",
    "        oll.append(y)\n",
    "\n",
    "ys.append(torch.cat(oll, dim=-1).cpu().numpy().squeeze())\n",
    "\n",
    "s.show()\n",
    "Audio(data=sum(ys), rate=48000, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53465ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = microtones.JIVector(syntonic_commas_down=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ea429",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.calculate_ji_markup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HEJIAccidental:  # give a _tweaks value?\n",
    "    def __init__(\n",
    "        self,\n",
    "        accidental_markup=None,\n",
    "    ):\n",
    "        self.accidental_markup = accidental_markup\n",
    "\n",
    "\n",
    "class HEJIPitch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        fundamental=None,\n",
    "        ratio=None,\n",
    "    ):\n",
    "        self.fundamental = fundamental\n",
    "        self.ratio = ratio\n",
    "        self.bundle = microtones.make_ji_bundle(self.fundamental, self.ratio)\n",
    "        self.accidental = self._calculate_accidental_markup()\n",
    "        self.et_cent_deviation_markup = self._calculate_et_cent_deviation()\n",
    "        self.written_pitch = self._calculate_written_pitch()\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f\"{self.written_pitch}!\"  # do not allow to be unforced?\n",
    "        return s\n",
    "\n",
    "    def _calculate_accidental_markup(self):\n",
    "        accidental_markup = self.bundle.vector.calculate_ji_markup()\n",
    "        a = HEJIAccidental(accidental_markup)\n",
    "        return a\n",
    "\n",
    "    def _calculate_et_cent_deviation(self):\n",
    "        deviation = microtones.return_cent_deviation_markup(\n",
    "            ratio=self.ratio,\n",
    "            fundamental=self.fundamental,\n",
    "            chris=False,\n",
    "        )\n",
    "        return deviation\n",
    "\n",
    "    def _calculate_written_pitch(self):\n",
    "        temp_note = abjad.Note(self.fundamental, (1, 4))\n",
    "        microtones.tune_to_ratio(temp_note.note_head, self.ratio)\n",
    "        written_pitch = temp_note.written_pitch\n",
    "        return written_pitch\n",
    "\n",
    "    def _get_lilypond_format(self):\n",
    "        return str(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = HEJIPitch(\"c'\", \"5/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.accidental.accidental_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"d'8 f' a' d'' f'' gs'4 r8 e' gs' b' e'' gs'' a'4\"\n",
    "voice = abjad.Voice(string, name=\"RH_Voice\")\n",
    "staff = abjad.Staff([voice], name=\"RH_Staff\")\n",
    "score = abjad.Score([staff], name=\"Score\")\n",
    "abjad.show(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = abjad.Note(\"c'4\")\n",
    "staff = abjad.Staff([note])\n",
    "score = abjad.Score([staff])\n",
    "leaf = abjad.get.leaf(score, 0)\n",
    "abjad.attach(score, abjad.LilyPondLiteral('\\tune 5', site='before'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lilypond_file = abjad.LilyPondFile(\n",
    "    items=[\n",
    "        \"#(set-default-paper-size \\\"a4\\\" \\'portrait)\",\n",
    "        r\"#(set-global-staff-size 16)\",\n",
    "        \"\\\\include \\'microlily/he.ly\\'\",\n",
    "        score,\n",
    "        abjad.Block(name=\"layout\"),\n",
    "    ],\n",
    ")\n",
    "style = '\"dodecaphonic\"'\n",
    "lilypond_file[\"layout\"].items.append(fr\"\\accidentalStyle {style}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abjad.show(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "abjad.attach(p.accidental.accidental_markup, voice[5])\n",
    "abjad.show(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = abjad.NumberedPitch(12.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650cec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f058901",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = music21.stream.Part(id='part0')\n",
    "p0.insert(0, music21.meter.TimeSignature('5/4'))\n",
    "for m in measures:\n",
    "    p0.append(m)\n",
    "tempo = music21.tempo.MetronomeMark(referent=1.0, number=90.0)\n",
    "p0.measure(1).insert(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d755c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = music21.note.Note(quarterLength=1/3)\n",
    "one.pitch.frequency = 440*11/7\n",
    "add_microtone(one)\n",
    "\n",
    "two = music21.note.Note(quarterLength=1/3)\n",
    "two.pitch.frequency = 440*11/13\n",
    "two.articulations.append(music21.articulations.Staccato())\n",
    "add_microtone(two)\n",
    "\n",
    "sl1 = music21.spanner.Slur([one, two])\n",
    "\n",
    "rest1 = music21.note.Rest(1/3)\n",
    "\n",
    "rest = music21.note.Rest(4)\n",
    "\n",
    "s = music21.stream.Score(id='mainScore')\n",
    "p0 = music21.stream.Part(id='part0')\n",
    "\n",
    "m01 = music21.stream.Measure(number=1)\n",
    "\n",
    "m01.append(music21.dynamics.Dynamic('sfz'))\n",
    "m01.append(one)\n",
    "m01.append(two)\n",
    "m01.append(sl1)\n",
    "m01.append(rest1)\n",
    "m01.append(rest)\n",
    "\n",
    "for i in range(10):\n",
    "    mezura = deepcopy(m01)\n",
    "    if i % 3 == 2:\n",
    "        mezura.append(music21.layout.SystemLayout(isNew=True))\n",
    "    p0.append(mezura)\n",
    "\n",
    "tempo = music21.tempo.MetronomeMark(referent=1.0, number=90.0)\n",
    "p0.measure(1).insert(tempo)\n",
    "p0.insert(0, music21.meter.TimeSignature('5/4'))\n",
    "s.insert(0, p0)\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8758f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "one.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17ce4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
