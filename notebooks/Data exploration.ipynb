{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio.functional as AF\n",
    "import torchcrepe\n",
    "\n",
    "from einops import rearrange\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from performer.datamodules.components.ddsp_dataset import DDSPDataset\n",
    "from performer.utils.constants import *\n",
    "from performer.utils.helpers import freqs_to_cents, cents_to_bins\n",
    "from performer.utils.features import Loudness, get_f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from performer.models.components.harmonic_oscillator import HarmonicOscillator\n",
    "from performer.models.components.controller import Controller, TransformerController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7cc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = HarmonicOscillator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2abcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bok = Controller(64, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ef63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaka = TransformerController(n_harmonics=64, n_noise_filters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe462a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = torch.ones(1, 1, 250) * 440\n",
    "f0 += torch.randn_like(f0) * 10.\n",
    "loudness = torch.ones(1, 1, 250) * -40\n",
    "loudness += torch.randn_like(loudness) * 12.\n",
    "\n",
    "with torch.no_grad():\n",
    "    (_, master, harms), _ = kaka(f0, loudness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520245f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(master[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_sigmoid(x):\n",
    "    return 2 * torch.sigmoid(x) ** 2.3 + 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383991e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(modified_sigmoid(torch.linspace(-1, 1, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14bcba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = '/home/kureta/Music/Cello Samples/ArpAm-00000-.wav'\n",
    "y1, _ = librosa.load(wav_path, sr=48000, mono=False, dtype='float32')\n",
    "y2, _ = librosa.load(wav_path, sr=44100, mono=False, dtype='float32')\n",
    "y2 = AF.resample(torch.from_numpy(y2), 44100, 48000)\n",
    "\n",
    "y1.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331573e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DDSPDataset('../data/cello_samples.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.f0.shape, dataset.loudness.shape, dataset.audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.audio.unfold(1, 48000*4, 48000*1).transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ff551",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, amp, audio = dataset[13]\n",
    "plt.plot(f0[0])\n",
    "plt.show()\n",
    "plt.plot(amp[0])\n",
    "plt.show()\n",
    "Audio(data=audio, rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness = torch.cat([l['loudness'][0] for l in dataset.features]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness.min(), loudness.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Loudness().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = torch.stack([l['audio'] for l in dataset.features]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f45dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815bf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0s = []\n",
    "for wav in audios:\n",
    "    f0s.append(get_f0(wav.unsqueeze(0).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = torch.cat(f0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ffde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs[0, 0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ecc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amps = []\n",
    "for i in range(0, 6075, 25):\n",
    "    amps.append(calc.get_amp(audios[i:i+25].cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness = torch.cat(amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness = loudness.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness.max() - loudness.min(), loudness.min(), loudness.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096672dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness = loudness.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "\n",
    "n, bins, patches = plt.hist(loudness, 128)\n",
    "plt.title(\"Loudness Histogram\")\n",
    "plt.xlabel(\"Db\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "l_min = loudness.min()\n",
    "l_max = loudness.max()\n",
    "mean = loudness.mean()\n",
    "std = loudness.std()\n",
    "start = mean - std\n",
    "end = mean + std\n",
    "\n",
    "plt.xticks([mean, l_min, l_max, start, end, start-std, end+std])\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.axvline(x=l_min, linewidth=2, label=f'min={l_min:.2f}', color='k')\n",
    "plt.axvline(x=l_max, linewidth=2, label=f'max={l_max:.2f}', color='k')\n",
    "plt.axvline(x=mean, linewidth=2, label=f'mean={mean:.2f}', color='k', linestyle='dashed')\n",
    "plt.axvline(x=start, linewidth=2, label=f'-sigma={start:.2f}', color='g', linestyle='dashed')\n",
    "plt.axvline(x=end, linewidth=2, label=f'+sigma={end:.2f}', color='g', linestyle='dashed')\n",
    "plt.axvline(x=start-std, linewidth=2, label=f'-2sigma={start-std:.2f}', color='y', linestyle='dashed')\n",
    "plt.axvline(x=end+std, linewidth=2, label=f'+2sigma={end+std:.2f}', color='y', linestyle='dashed')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(norm.cdf((loudness - mean) / std), 128)\n",
    "plt.title(\"Loudness Histogram\")\n",
    "plt.xlabel(\"Normalized Db\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d93134",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = torch.cat([l['f0'][0] for l in dataset.features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dba620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_to_cents(bins):\n",
    "    \"\"\"Converts pitch bins to cents\"\"\"\n",
    "    cents = 20 * bins + 1997.3794084376191\n",
    "\n",
    "    # Trade quantization error for noise\n",
    "    return cents\n",
    "\n",
    "def cents_to_frequency(cents):\n",
    "    \"\"\"Converts cents to frequency in Hz\"\"\"\n",
    "    return 10 * 2 ** (cents / 1200)\n",
    "\n",
    "def freqs_to_cents(freq):\n",
    "    return 1200 * torch.log2(freq / 10.)\n",
    "\n",
    "def cents_to_bins(cents):\n",
    "    return (cents - 1997.3794084376191) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = cents_to_bins(freqs_to_cents(f0)) / 359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = f0.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4392156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "\n",
    "n, bins, patches = plt.hist(f0, 360)\n",
    "plt.title(\"F0 Histogram\")\n",
    "plt.xlabel(\"Normalized pitch\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "l_min = f0.min()\n",
    "l_max = f0.max()\n",
    "mean = f0.mean()\n",
    "std = f0.std()\n",
    "start = mean - std\n",
    "end = mean + std\n",
    "\n",
    "plt.xticks([mean, l_min, l_max, start, end, start-std, end+std])\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.axvline(x=l_min, linewidth=2, label=f'min={l_min:.2f}', color='k')\n",
    "plt.axvline(x=l_max, linewidth=2, label=f'max={l_max:.2f}', color='k')\n",
    "plt.axvline(x=mean, linewidth=2, label=f'mean={mean:.2f}', color='k', linestyle='dashed')\n",
    "plt.axvline(x=start, linewidth=2, label=f'-sigma={start:.2f}', color='g', linestyle='dashed')\n",
    "plt.axvline(x=end, linewidth=2, label=f'+sigma={end:.2f}', color='g', linestyle='dashed')\n",
    "plt.axvline(x=start-std, linewidth=2, label=f'-2sigma={start-std:.2f}', color='y', linestyle='dashed')\n",
    "plt.axvline(x=end+std, linewidth=2, label=f'+2sigma={end+std:.2f}', color='y', linestyle='dashed')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amp(example):\n",
    "    b, c, _ = example.shape\n",
    "    example = rearrange(example, \"b c t -> (b c) t\")\n",
    "    example = torch.nn.functional.pad(example, (19200 // 2, 19200 // 2))\n",
    "    example = example.unfold(1, 19200, HOP_LENGTH)\n",
    "    _, f, _ = example.shape\n",
    "    example = rearrange(example, \"(b c) f t -> (b f) c t\", b=b, c=c, f=f)\n",
    "\n",
    "    amp = AF.loudness(example, SAMPLE_RATE)\n",
    "    amp = rearrange(amp, \"(b f) -> b f\", b=b, f=f).unsqueeze(1)\n",
    "\n",
    "    return amp\n",
    "\n",
    "\n",
    "def get_pitch(x, device='cuda'):\n",
    "    # to mono\n",
    "    x = AF.resample(x.mean(1), SAMPLE_RATE, CREPE_SAMPLE_RATE)\n",
    "    f0 = torchcrepe.predict(x,\n",
    "                            sample_rate=CREPE_SAMPLE_RATE,\n",
    "                            hop_length=CREPE_HOP_LENGTH,\n",
    "                            fmin=31.7,\n",
    "                            decoder=torchcrepe.decode.weighted_argmax,\n",
    "                            device=device, return_periodicity=False).unsqueeze(1)\n",
    "\n",
    "    return f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1968c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, amp, audio = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a48175",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2641fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = get_amp(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "bok = get_pitch(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e925c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bok.shape, shit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = librosa.stft(audio[0].mean(0).numpy(), n_fft=N_FFT, hop_length=HOP_LENGTH, pad_mode='reflect').T\n",
    "print(s.shape)\n",
    "# Compute power.\n",
    "amplitude = np.abs(s)\n",
    "power = amplitude**2\n",
    "\n",
    "frequencies = librosa.fft_frequencies(sr=SAMPLE_RATE, n_fft=N_FFT)\n",
    "a_weighting = librosa.A_weighting(frequencies)[None, :]\n",
    "weighting = 10**(a_weighting/10)\n",
    "power = power * weighting\n",
    "\n",
    "power = np.mean(power, axis=-1)\n",
    "# loudness = np.log(power*100 + 1)\n",
    "loudness = librosa.power_to_db(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.stack([dataset[0][2], dataset[1][2], dataset[2][2], dataset[3][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.stft(batch.mean(1), n_fft=N_FFT, hop_length=HOP_LENGTH, window=torch.hann_window(N_FFT), return_complex=True, pad_mode='reflect')\n",
    "s = s.transpose(1, 2)\n",
    "\n",
    "# Compute power.\n",
    "amplitude = torch.abs(s)\n",
    "power = amplitude**2\n",
    "\n",
    "frequencies = torch.from_numpy(librosa.fft_frequencies(sr=SAMPLE_RATE, n_fft=N_FFT).astype('float32'))\n",
    "a_weighting = torch.from_numpy(librosa.A_weighting(frequencies)[None, None, :].astype('float32'))\n",
    "weighting = 10**(a_weighting/10)\n",
    "power = power * weighting\n",
    "\n",
    "power = torch.mean(power, axis=-1)\n",
    "torchness = 10.0 * np.log10(np.maximum(1e-10, power))\n",
    "torchness = np.maximum(torchness, torchness.max() - 80.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae215273",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness.shape, loudness.min(), loudness.max(), torchness.shape, torchness.min(), torchness.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchness.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot((torch.nan_to_num(shit[0, 0], nan=-70)))\n",
    "plt.plot((loudness))\n",
    "plt.plot((torchness[0]))\n",
    "plt.show()\n",
    "plt.plot(bok[0, 0])\n",
    "plt.show()\n",
    "Audio(data=audio[0], rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot(torch.nan_to_num(shit[0], nan=-70))\n",
    "plt.show()\n",
    "plt.plot(f[0])\n",
    "plt.show()\n",
    "Audio(data=audio[0], rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = torch.stack([f['audio'] for f in dataset.features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "amps = []\n",
    "for i in range(0, 6075, 25):\n",
    "    print(i)\n",
    "    amps.append(get_amp(audios[i:i+25].cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747114e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "amps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = torch.cat([a.cpu() for a in amps], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfa939",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nan_to_num_(shit, nan=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33738785",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit[shit==100.] = -70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shit.min(), shit.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot((shit[idx] + 70) / 70)\n",
    "plt.show()\n",
    "plt.plot(dataset.features[idx]['f0'][0])\n",
    "plt.show()\n",
    "Audio(data=audios[idx, 0], rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_range = 70  # dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 250\n",
    "hop_size = 48000 // frame_rate\n",
    "hop_size, 48000 * 5 // hop_size  # 5 seconds in samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2463e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_harmonics = 60 * 3\n",
    "n_noise = 65 * 3\n",
    "n_harmonics, n_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568c516",
   "metadata": {},
   "source": [
    "- normalize f0:\n",
    "  - `f0 = cents_to_bins(freqs_to_cents(f0)) / 359`\n",
    "- un-normalize f0:\n",
    "  - `f0 = cents_to_freqs(bins_to_cents(f0 * 359))`\n",
    "- normalize dB:\n",
    "  - `db = (db + 70) / 70`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b946eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AF.resample(dataset.features[0]['audio'].unsqueeze(0).mean(1), SAMPLE_RATE, CREPE_SAMPLE_RATE)\n",
    "f0 = torchcrepe.predict(x,\n",
    "                        sample_rate=16000,\n",
    "                        hop_length=CREPE_HOP_LENGTH,\n",
    "                        fmin=31.7,\n",
    "                        decoder=torchcrepe.decode.weighted_argmax,\n",
    "                        device='cuda', return_periodicity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2391702",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e695d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "plt.plot(cents_to_bins(freqs_to_cents(f0[0]).cpu().numpy()))\n",
    "plt.show()\n",
    "# plt.matshow(prod[0].cpu().numpy(), origin='lower')\n",
    "# plt.show()\n",
    "Audio(data=dataset.features[0]['audio'].numpy(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa578c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.random.rand(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log((tt+1).mean()), np.log(tt + 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe41ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
