{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29941440",
   "metadata": {},
   "source": [
    "# Gratias, Deo (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc859ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext abjad_notebook\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import abjad\n",
    "import librosa\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "from performer.composition.score import Renderer, parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c76c2",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ae54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 48000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "OUTPUT_DIR = Path(\"../gratias-deo\")\n",
    "DEO_PATH = OUTPUT_DIR / \"deo-original.wav\"\n",
    "ABJAD_INCLUDE_DIR = abjad.configuration.Configuration().abjad_directory / \"abjad/scm\"\n",
    "\n",
    "FLT_CKPT = \"../checkpoints/flute_longrun.ckpt\"\n",
    "VLN_CKPT = \"../checkpoints/violin_longrun.ckpt\"\n",
    "VLC_CKPT = \"../checkpoints/cello_longrun.ckpt\"\n",
    "DRM_CKPT = \"../checkpoints/drums_baseline.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624609c",
   "metadata": {},
   "source": [
    "## Some lily files to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "abjad_ily = f'\\\\include \"{ABJAD_INCLUDE_DIR}/abjad.ily\"\\n'\n",
    "\n",
    "event_listener = r\"\"\"#(ly:set-option 'relative-includes #t)\n",
    "\\include \"./event-listener.ly\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fcd0fb",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio_file(file_path, data):\n",
    "    sf.write(f\"{OUTPUT_DIR}/{file_path}\", data.T, SAMPLE_RATE, subtype=\"PCM_24\")\n",
    "\n",
    "\n",
    "def get_notes_file(pdf_path, instrument_name):\n",
    "    notes_path = pdf_path.parent / f\"{pdf_path.stem}-{instrument_name}.notes\"\n",
    "\n",
    "    return notes_path\n",
    "\n",
    "\n",
    "def slur_parts(voice, counts):\n",
    "    notes = abjad.select.notes(voice)\n",
    "    parts = abjad.select.partition_by_counts(notes, counts, cyclic=True)\n",
    "    for part in parts:\n",
    "        first_note, last_note = part[0], part[-1]\n",
    "        accent = abjad.Articulation(\"accent\")\n",
    "        start_slur = abjad.StartSlur()\n",
    "        abjad.attach(accent, first_note)\n",
    "        abjad.attach(start_slur, first_note)\n",
    "        staccato = abjad.Articulation(\"staccato\")\n",
    "        stop_slur = abjad.StopSlur()\n",
    "        abjad.attach(staccato, last_note)\n",
    "        abjad.attach(stop_slur, last_note)\n",
    "\n",
    "\n",
    "def tupletize_notes(voice, counts, modulus):\n",
    "    notes = abjad.select.notes(voice)\n",
    "    parts = abjad.select.partition_by_counts(notes, counts, cyclic=True)\n",
    "    for i, part in enumerate(parts):\n",
    "        if i % len(counts) == modulus:\n",
    "            abjad.mutate.wrap(part, abjad.Tuplet(\"3:2\"))\n",
    "\n",
    "\n",
    "# The rhythm of the piece is based on even number fibonacci patterns concatenated\n",
    "# with their mirror images.\n",
    "def get_fibonacci_pattern(n=3):\n",
    "    previous_pattern = [2]\n",
    "    current_pattern = []\n",
    "    while n >= 0:\n",
    "        for m in previous_pattern:\n",
    "            if m == 2:\n",
    "                current_pattern.extend([2, 1])\n",
    "            else:\n",
    "                current_pattern.append(2)\n",
    "        n = n - 1\n",
    "        previous_pattern = current_pattern\n",
    "        current_pattern = []\n",
    "\n",
    "    return previous_pattern\n",
    "\n",
    "\n",
    "def fibonacci_generator():\n",
    "    pattern = [2, 1]\n",
    "    step = -1\n",
    "\n",
    "    while True:\n",
    "        # yield elements of current pattern\n",
    "        for e in pattern:\n",
    "            yield e\n",
    "\n",
    "        pattern = get_fibonacci_pattern(step)\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e290148",
   "metadata": {},
   "outputs": [],
   "source": [
    "flute_renderer = Renderer(FLT_CKPT, \"cpu\")\n",
    "drum_renderer = Renderer(DRM_CKPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d0890",
   "metadata": {},
   "source": [
    "## Load `Deo` sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98596def",
   "metadata": {},
   "outputs": [],
   "source": [
    "deo_audio, sr = librosa.load(DEO_PATH, sr=SAMPLE_RATE, mono=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5df00",
   "metadata": {},
   "source": [
    "## Do STFT transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2457165",
   "metadata": {},
   "outputs": [],
   "source": [
    "deo_complex_stft = librosa.stft(deo_audio, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "deo_db_stft = librosa.amplitude_to_db(np.abs(deo_complex_stft), top_db=120)\n",
    "deo_db_stft_mono = deo_db_stft.mean(axis=0)\n",
    "\n",
    "fft_frequencies = librosa.fft_frequencies(sr=SAMPLE_RATE, n_fft=N_FFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34b0e6",
   "metadata": {},
   "source": [
    "## Pick most prominent STFT bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select bins with mean dB value greater than `db_threshold`\n",
    "db_threshold = -24.0\n",
    "mean_db_per_bin = deo_db_stft_mono.mean(axis=1)\n",
    "criterion = mean_db_per_bin > db_threshold\n",
    "\n",
    "selected_bins = np.where(criterion)[0]\n",
    "\n",
    "# sort selected bins by mean dB\n",
    "sorted_selected_bins = sorted(selected_bins, key=lambda x: mean_db_per_bin[x])\n",
    "\n",
    "# manual sub selection\n",
    "select_indices = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    12,\n",
    "    13,\n",
    "    14,\n",
    "    15,\n",
    "    17,\n",
    "    18,\n",
    "    19,\n",
    "    20,\n",
    "    21,\n",
    "    22,\n",
    "    24,\n",
    "    27,\n",
    "    28,\n",
    "    29,\n",
    "    30,\n",
    "    31,\n",
    "]\n",
    "sorted_selected_bins = [sorted_selected_bins[idx] for idx in select_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e400f3b",
   "metadata": {},
   "source": [
    "## Get a separate STFT  for each selected bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_complex_stfts = []\n",
    "\n",
    "for idx in sorted_selected_bins:\n",
    "    mask = np.zeros_like(deo_complex_stft)\n",
    "    mask[:, idx, :] = 1\n",
    "    masked_stft = deo_complex_stft * mask\n",
    "\n",
    "    masked_complex_stfts.append(masked_stft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd9807",
   "metadata": {},
   "source": [
    "## Generate melody, canon, and harmony audio files for each STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "canon_partials = []\n",
    "\n",
    "for masked_complex_stft in masked_complex_stfts:\n",
    "    y = librosa.istft(masked_complex_stft, hop_length=HOP_LENGTH)\n",
    "    canon_partials.append(y)\n",
    "\n",
    "# prepare sounds\n",
    "canon = np.concatenate(np.cumsum(canon_partials, axis=0), axis=1)\n",
    "melody = np.concatenate(canon_partials, axis=1)\n",
    "harmony = np.sum(canon_partials, axis=0)\n",
    "\n",
    "save_audio_file(\"deo-melody.wav\", melody)\n",
    "save_audio_file(\"deo-canon.wav\", canon)\n",
    "save_audio_file(\"deo-harmony.wav\", harmony)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf1a86",
   "metadata": {},
   "source": [
    "## Prepare the theme for Canon for 1 Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a6968",
   "metadata": {},
   "source": [
    "### Prepare notes, voice, staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd3e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get note dynamics. we'll manually add dynamics and hairpins to score/\n",
    "dynamics = np.array([\"ppp\", \"pp\", \"p\", \"mp\", \"mf\", \"f\", \"ff\", \"fff\"])\n",
    "\n",
    "note_dynamics = mean_db_per_bin[sorted_selected_bins]\n",
    "note_dynamics -= note_dynamics.min()\n",
    "note_dynamics /= note_dynamics.max()\n",
    "\n",
    "print(np.round(note_dynamics / (1 / 7)).astype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cce66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_names = librosa.hz_to_note(fft_frequencies[sorted_selected_bins])\n",
    "\n",
    "abjad_notes = [abjad.Note.from_pitch_and_duration(n.replace(\"â™¯\", \"#\"), (3, 4)) for n in note_names]\n",
    "\n",
    "# Add quarter sharps to notes\n",
    "quarter_sharps = (np.round(2 * librosa.hz_to_midi(fft_frequencies[sorted_selected_bins])) / 2) % 1\n",
    "abjad_quarter_sharp = abjad.Accidental(\"quarter sharp\")\n",
    "for idx, qs in enumerate(quarter_sharps):\n",
    "    if qs == 0:\n",
    "        continue\n",
    "    base_name = abjad_notes[idx].written_pitch.name[0]\n",
    "    ticks = abjad_notes[idx].written_pitch.octave.ticks\n",
    "    base_name += ticks\n",
    "    new_accidental = abjad_notes[idx].written_pitch.accidental + abjad_quarter_sharp\n",
    "    new_note = abjad.NamedPitch(base_name, accidental=new_accidental)\n",
    "    abjad_notes[idx].written_pitch = new_note\n",
    "\n",
    "\n",
    "canon_voice = abjad.Voice(abjad_notes, name=\"Voice_1\")\n",
    "canon_staff = abjad.Staff([canon_voice], name=\"Canon_1\")\n",
    "\n",
    "# add dynamics manually\n",
    "abjad.hairpin(\"pp < p\", canon_voice[:5])\n",
    "abjad.hairpin(\"< mp\", canon_voice[5:16])\n",
    "abjad.hairpin(\"< f\", canon_voice[16:20])\n",
    "# abjad.hairpin(\"< ff\", canon_voice[20:22])\n",
    "abjad.hairpin(\"< ff\", canon_voice[22:])\n",
    "abjad.override(canon_voice[0]).DynamicLineSpanner.staff_padding = 4\n",
    "\n",
    "# Add instrument name\n",
    "instrument_name = \"Flute\"\n",
    "markup = abjad.Markup(f'\\\\markup \"{instrument_name}\"')\n",
    "abjad.attach(abjad.InstrumentName(markup), canon_voice[0])\n",
    "\n",
    "# add ottava marks manually\n",
    "abjad.ottava(canon_voice[:18], start_ottava=abjad.Ottava(2), stop_ottava=abjad.Ottava(0))\n",
    "\n",
    "# calculate tempo. assume 3/4 time signature. harmony should be 1 bar long, so 3 quarter notes.\n",
    "# we can find number of quarter notes per minute.\n",
    "tempo = 60 * 3 * SAMPLE_RATE / harmony.shape[1]\n",
    "print(f\"BPM: {tempo:.2f}\")\n",
    "\n",
    "# add tempo mark. event listener requires integer tempo (I guess)\n",
    "mark = abjad.MetronomeMark((1, 4), int(tempo))\n",
    "abjad.attach(mark, canon_voice[0])\n",
    "\n",
    "# add time signature\n",
    "time_signature = abjad.TimeSignature((3, 4))\n",
    "abjad.attach(time_signature, canon_voice[0])\n",
    "\n",
    "# prepare and preview file\n",
    "lilypond_file = abjad.LilyPondFile([event_listener, abjad_ily, canon_staff])\n",
    "abjad.show(lilypond_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18ca36",
   "metadata": {},
   "source": [
    "### Export event list, parse, and render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path, *_ = abjad.persist.as_pdf(lilypond_file, OUTPUT_DIR / \"gratias-deo.pdf\")\n",
    "pdf_path = Path(pdf_path)\n",
    "notes_path = get_notes_file(pdf_path, instrument_name)\n",
    "\n",
    "notes = parser(notes_path)\n",
    "y = flute_renderer.render(notes)\n",
    "\n",
    "Audio(data=y, rate=48000, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b022b",
   "metadata": {},
   "source": [
    "# Write human parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4840b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pitch:\n",
    "    def __init__(self, name, accidental, octave):\n",
    "        self.name = name\n",
    "        self.accidental = accidental\n",
    "        self.octave = octave\n",
    "\n",
    "    @property\n",
    "    def pitch(self):\n",
    "        return abjad.NamedPitch(name=self.name, accidental=self.accidental, octave=self.octave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ccd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all to a single octave\n",
    "pcs = []\n",
    "for idx, n in enumerate(abjad_notes):\n",
    "    base_name = abjad_notes[idx].written_pitch.name[0]\n",
    "    accidental = abjad_notes[idx].written_pitch.accidental\n",
    "    octave = 5\n",
    "    pc = Pitch(base_name, accidental, octave)\n",
    "    if pc not in pcs:\n",
    "        pcs.append(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_voice = abjad.Voice([abjad.Note(pc.pitch, (1, 16)) for pc in pcs], name=\"Scale Voice\")\n",
    "scale_staff = abjad.Staff([scale_voice], name=\"Scale Staff\")\n",
    "\n",
    "# Add instrument name\n",
    "instrument_name = \"Flute II\"\n",
    "markup = abjad.Markup(f'\\\\markup \"{instrument_name}\"')\n",
    "abjad.attach(abjad.InstrumentName(markup), scale_voice[0])\n",
    "\n",
    "# add tempo mark. event listener requires integer tempo (I guess)\n",
    "mark = abjad.MetronomeMark((1, 4), 130)\n",
    "abjad.attach(mark, scale_voice[0])\n",
    "\n",
    "# add time signature\n",
    "time_signature = abjad.TimeSignature((4, 4))\n",
    "abjad.attach(time_signature, scale_voice[0])\n",
    "\n",
    "# add dynamics\n",
    "abjad.attach(abjad.Dynamic(\"mp\"), scale_voice[0])\n",
    "abjad.override(scale_voice[0]).DynamicLineSpanner.staff_padding = 4\n",
    "\n",
    "\n",
    "# adjust durations\n",
    "notes = abjad.select.notes(scale_voice)\n",
    "fibonacci = fibonacci_generator()\n",
    "fib = [next(fibonacci) for i in range(len(notes))]\n",
    "for n, f in zip(notes, fib):\n",
    "    if f == 1:\n",
    "        abjad.mutate.scale(n, abjad.Fraction(1, 2))\n",
    "\n",
    "# add slurs\n",
    "slur_parts(scale_voice, [3 if n == 1 else 5 for n in fib])\n",
    "\n",
    "# prepare and preview file\n",
    "lilypond_file = abjad.LilyPondFile([event_listener, abjad_ily, scale_staff])\n",
    "abjad.show(lilypond_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path, *_ = abjad.persist.as_pdf(lilypond_file, OUTPUT_DIR / \"base-scale.pdf\")\n",
    "pdf_path = Path(pdf_path)\n",
    "notes_path = get_notes_file(pdf_path, instrument_name)\n",
    "\n",
    "\n",
    "notes = parser(notes_path)\n",
    "y = flute_renderer.render(notes)\n",
    "\n",
    "Audio(data=y, rate=48000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df26b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "chords = abjad.select.partition_by_counts(pcs, [3, 5], cyclic=True)\n",
    "phrases = sum([c * 5 for c in chords], start=[])\n",
    "test_voice = abjad.Voice([abjad.Note(pc.pitch, (1, 16)) for pc in phrases], name=\"Test Voice\")\n",
    "test_staff = abjad.Staff([test_voice], name=\"Test Staff\")\n",
    "\n",
    "# Add instrument name\n",
    "instrument_name = \"Flute\"\n",
    "markup = abjad.Markup(f'\\\\markup \"{instrument_name}\"')\n",
    "abjad.attach(abjad.InstrumentName(markup), test_voice[0])\n",
    "\n",
    "# add tempo mark. event listener requires integer tempo (I guess)\n",
    "mark = abjad.MetronomeMark((1, 4), 130)\n",
    "abjad.attach(mark, test_voice[0])\n",
    "\n",
    "# add time signature\n",
    "time_signature = abjad.TimeSignature((3, 8))\n",
    "abjad.attach(time_signature, test_voice[0])\n",
    "\n",
    "# add dynamics\n",
    "abjad.attach(abjad.Dynamic(\"mp\"), test_voice[0])\n",
    "abjad.override(test_voice[0]).DynamicLineSpanner.staff_padding = 4\n",
    "\n",
    "# prepare and preview file\n",
    "lilypond_file = abjad.LilyPondFile([event_listener, abjad_ily, test_staff])\n",
    "abjad.show(lilypond_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path, *_ = abjad.persist.as_pdf(lilypond_file, OUTPUT_DIR / \"test-scale.pdf\")\n",
    "pdf_path = Path(pdf_path)\n",
    "notes_path = get_notes_file(pdf_path, instrument_name)\n",
    "\n",
    "\n",
    "notes = parser(notes_path)\n",
    "y = flute_renderer.render(notes)\n",
    "\n",
    "Audio(data=y, rate=48000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in notes.notes:\n",
    "    n.f0 /= 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841fcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in notes.notes:\n",
    "    n.f0 += np.random.randn(*n.f0.shape) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in notes.notes:\n",
    "    n.envelope.gap_percent_duration = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdacb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = drum_renderer.render(notes)\n",
    "\n",
    "Audio(data=y, rate=48000, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93823d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
