{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf5ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b40c82",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "Maybe pick peaks, or lowpass filter or something. I guess we are taking all the indices surrounding a peak in this method.\n",
    "\n",
    "Especially for the FFT case, try to fin most important bands somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4b406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEO_PATH = \"/home/kureta/Music/deo.wav\"\n",
    "SAMPLE_RATE = 48000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14794d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(DEO_PATH, sr=SAMPLE_RATE, mono=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a60ddf",
   "metadata": {},
   "source": [
    "## Canon for 1 Voice in STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a1db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stft = librosa.stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "sdb = librosa.amplitude_to_db(np.abs(stft), top_db=120)\n",
    "mono = sdb.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = librosa.fft_frequencies(sr=SAMPLE_RATE, n_fft=N_FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532ecbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = np.where(mono.mean(axis=1) > -24.)[0]\n",
    "indices = sorted(indices, key=lambda x: mono.mean(axis=1)[x])\n",
    "indices = np.array(indices)\n",
    "# indices = indices[(indices > 4) & (indices < 128)]\n",
    "print(len(indices))\n",
    "\n",
    "sounds = []\n",
    "previous = None\n",
    "cents = []\n",
    "hzs = []\n",
    "for i, idx in enumerate(indices):\n",
    "    pick = np.zeros_like(stft)\n",
    "    pick[:, idx, :] = 1\n",
    "    modified = stft * pick\n",
    "    midi_cents = librosa.hz_to_midi(np.maximum(freq[idx], 1e-5))\n",
    "    cents.append(midi_cents)\n",
    "    hzs.append(freq[idx])\n",
    "\n",
    "    image = librosa.feature.melspectrogram(S=modified, sr=SAMPLE_RATE, hop_length=HOP_LENGTH)\n",
    "    image = np.log(np.maximum(np.abs(image).mean(0), 1e-5))\n",
    "    image -= image.min()\n",
    "    image /= np.maximum(image.max(), 1e-5)\n",
    "    image = 1-image\n",
    "    previous = image if previous is None else previous + image\n",
    "\n",
    "    img.imsave(f'stft-frames/{i}.png', image, origin='lower', cmap='gray')\n",
    "    img.imsave(f'stft-frames/c-{i}.png', previous, origin='lower', cmap='gray')\n",
    "\n",
    "    # modified = np.repeat(modified, 3, axis=2)\n",
    "    s = librosa.istft(modified, hop_length=HOP_LENGTH)\n",
    "    sounds.append(s)\n",
    "\n",
    "canon = np.concatenate(np.cumsum(sounds, axis=0), axis=1)\n",
    "melody = np.concatenate(sounds, axis=1)\n",
    "harmony = np.sum(sounds, axis=0)\n",
    "loop = np.concatenate([harmony] * 8, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b71e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 18, 19, 20, 22, 24]  # 27, 29, 31\n",
    "select_indices = [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 30, 31]\n",
    "picked_sounds = [sounds[idx] for idx in select_indices]\n",
    "\n",
    "melody = np.concatenate(picked_sounds, axis=1)\n",
    "canon = np.concatenate(np.cumsum(picked_sounds, axis=0), axis=1)\n",
    "melody = np.concatenate(picked_sounds, axis=1)\n",
    "harmony = np.sum(picked_sounds, axis=0)\n",
    "loop = np.concatenate([harmony] * 8, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in select_indices:\n",
    "    sf.write(f'../sounds/{idx}.wav', sounds[idx].T, SAMPLE_RATE, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f6601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Audio(data=canon, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df5acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Audio(data=melody, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c577e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=harmony, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=loop, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd5afa-19f2-42b0-b908-d2813c8003fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sf.write('/home/kureta/Downloads/deo-solo.wav', melody.T, SAMPLE_RATE, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8ed6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, sound in enumerate(sounds):\n",
    "    sf.write(f'/home/kureta/Music/deo-{idx+1:02d}.wav', sound.T, SAMPLE_RATE, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb19fa",
   "metadata": {},
   "source": [
    "## Music 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5460806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cents_ = [cents[idx] for idx in select_indices]\n",
    "# cents_.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df30166",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = stream.Stream()\n",
    "for i, j in enumerate(cents_):\n",
    "    p = pitch.Pitch(j - 12)\n",
    "    s.insert(i, note.Note(p))\n",
    "s.show()\n",
    "s.show('midi')\n",
    "s.write('midi', fp='/home/kureta/Downloads/deodorant.midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876d105",
   "metadata": {},
   "source": [
    "## Make it play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a61061",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 48000\n",
    "CREPE_SAMPLE_RATE = 16000\n",
    "SR_RATIO = SAMPLE_RATE // CREPE_SAMPLE_RATE\n",
    "CREPE_N_FFT = 1024\n",
    "N_FFT = 1024 * SR_RATIO\n",
    "\n",
    "# TODO: FRAME_RATE should be adjustable but valid values depend on audio example duration\n",
    "FRAME_RATE = 250\n",
    "HOP_LENGTH = SAMPLE_RATE // FRAME_RATE\n",
    "CREPE_HOP_LENGTH = HOP_LENGTH // SR_RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from performer.models.ddsp_module import DDSP\n",
    "from performer.utils.features import Loudness, get_f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d295e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, device):\n",
    "        self.ld = Loudness().to(device)\n",
    "    \n",
    "    def do(self, y):\n",
    "        if (diff := len(y) % HOP_LENGTH) != 0:\n",
    "            F.pad(y, (0, HOP_LENGTH - diff))\n",
    "        \n",
    "        audio = F.pad(y[None, None, :], (N_FFT // 2, N_FFT // 2))\n",
    "        loudness = self.ld.get_amp(audio)\n",
    "        f0 = get_f0(audio)\n",
    "        \n",
    "        return f0, loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vln_ckpt = '../checkpoints/violin_longrun.ckpt'\n",
    "vlc_ckpt = '../checkpoints/cello_longrun.ckpt'\n",
    "flt_ckpt = '../checkpoints/flute_longrun.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model = DDSP.load_from_checkpoint(vlc_ckpt, map_location='cpu')\n",
    "    model = model.to('cpu')\n",
    "    model.eval()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocess('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e487572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x: torch.Tensor, window_size: int) -> torch.Tensor:\n",
    "    # Compute the moving average using a sliding window\n",
    "    weights = torch.ones(window_size) / window_size\n",
    "    x_avg = torch.nn.functional.conv1d(x, weights.view(1, 1, -1), padding=window_size//2)\n",
    "\n",
    "    return x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(cents_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortado = sorted(list(set(np.round(cents_, 1) % 12)))\n",
    "print(sorted(list(set([f'{s:.1f}' for s in sortado]))))\n",
    "print([f'{n:.1f}' for n in np.diff(sortado)])\n",
    "octave_reduced = [0.1, 0.5, 1.3, 3.0, 3.9, 4.8, 5.1, 5.4, 6.2, 7., 7.3, 8.3, 8.7, 9, 9.2, 10.1, 10.7, 11.7]\n",
    "centos = [o + 60 for o in octave_reduced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([np.round(cents[idx] % 12, 1) for idx in select_indices])\n",
    "print(octave_reduced)\n",
    "print(len(octave_reduced))\n",
    "np.diff(octave_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melisma = [np.round(cents[idx] % 12, 1) for idx in select_indices]\n",
    "print([octave_reduced.index(m) for m in melisma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c738c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0s = []\n",
    "amps = []\n",
    "for idx, sound, cc in zip(select_indices, picked_sounds, centos):\n",
    "    prepared = torch.from_numpy(sound.mean(axis=0)).float().cuda()\n",
    "    prepared /= prepared.abs().max()\n",
    "    f0, amp = preprocessor.do(prepared)\n",
    "    \n",
    "    f0[..., :] = librosa.midi_to_hz(cc - 12)\n",
    "    \n",
    "    f0s.append(f0)\n",
    "    amps.append(amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a89f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amps = [amps[11]] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_batch = torch.cat(f0s)\n",
    "# averaged = moving_average(f0_batch.cpu(), 5)\n",
    "# f0_batch *= 2 ** (-5/12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d2098",
   "metadata": {},
   "source": [
    "for idx, val in enumerate(f0_batch):\n",
    "    condition = torch.abs(torch.log2(val) - torch.log2(val.median()))\n",
    "    f0_batch[idx][(condition > 1/12)] = val.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "zaks = []\n",
    "for f0, amp in zip(f0_batch, amps):\n",
    "    with torch.inference_mode():\n",
    "        y = model(f0.unsqueeze(0).cpu(), amp.cpu())\n",
    "\n",
    "    zaks.append(y.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df409e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, y in enumerate(zaks):\n",
    "    sf.write(f'../sounds/ordered-{idx}.wav', y.T, SAMPLE_RATE, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zak_canon = np.concatenate(np.cumsum(zaks, axis=0), axis=1)\n",
    "zak_melody = np.concatenate(zaks, axis=1)\n",
    "zak_harmony = np.sum(zaks, axis=0)\n",
    "zak_loop = np.concatenate([zak_harmony] * 8, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=zak_melody, rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b80ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
